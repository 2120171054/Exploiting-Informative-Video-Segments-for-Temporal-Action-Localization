import torch
import os
import numpy as np
from numpy.random import randint
import pandas as pd
import time
import sys
sys.path.append('/mnt/sdb/mnt/sda/sunche/work/TAL-attention/')
from attention_network_test_batch_THUMOS_cls_newreg_bigru_30 import *
def My_Pooling_full(prop_indices,vid,index,val_mode=False):
    if val_mode==False:
        savepath='/mnt/sdb/mnt/sda/sunche/work/PGCN-master/mydata2_train/'
    else:
        savepath='/mnt/sdb/mnt/sda/sunche/work/PGCN-master/mydata2_val/'
    features=np.load(savepath+vid+'.npy',allow_pickle=True).item()
    fts_all_act = []
    fts_all_comp = []
    for prop in prop_indices:

        act_s = prop[0]
        act_e = prop[1]
        comp_s = prop[2]
        comp_e = prop[3]
        key=[act_s,act_e,comp_s,comp_e]
        comp_ft=features[str(key)]
        # comp_ft[0:1200]=comp_ft[0:1200]/np.linalg.norm(comp_ft[0:1200])
        # comp_ft[1200:2400]=comp_ft[1200:2400]/np.linalg.norm(comp_ft[1200:2400])
        # comp_ft[2400:3600]=comp_ft[2400:3600]/np.linalg.norm(comp_ft[2400:3600])
        act_ft=comp_ft[1200:2400].copy()
        act_ft=torch.from_numpy(act_ft)
        comp_ft=torch.from_numpy(comp_ft)
        fts_all_act.append(act_ft)
        fts_all_comp.append(comp_ft)
        

    fts_all_act = torch.stack(fts_all_act)
    fts_all_comp = torch.stack(fts_all_comp)

    return fts_all_act, fts_all_comp
def My_Pooling_test(index):
    savepath='/mnt/sdb/mnt/sda/sunche/work/PGCN-master/mydata_test/'
    fts_all_act=np.load(savepath+'fts_all_act_'+str(index)+'.npy')
    fts_all_comp=np.load(savepath+'fts_all_comp_'+str(index)+'.npy')
    return torch.from_numpy(fts_all_act),torch.from_numpy(fts_all_comp)
def I3D_Pooling(prop_indices, vid, ft_path, n_frame, n_seg=4):

    ft_tensor = torch.load(os.path.join(ft_path, vid)).float()
    fts_all_act = []
    fts_all_comp = []
    comp_all_len = []
    for prop in prop_indices:

        act_s = prop[0]
        act_e = prop[1]
        comp_s = prop[2]
        comp_e = prop[3]

        start_ft,start_len = feature_pooling(comp_s, act_s, vid,
                                  n_frame, n_seg, 'max', ft_tensor)
        end_ft,end_len = feature_pooling(act_e, comp_e, vid,
                                  n_frame, n_seg, 'max', ft_tensor)
        act_ft,act_len = feature_pooling(act_s, act_e, vid,
                                  n_frame, n_seg, 'max', ft_tensor)
        comp_ft = [start_ft, act_ft, end_ft]
        comp_ft = torch.cat(comp_ft, dim=1)
        
        comp_len = torch.from_numpy(np.array([start_len,act_len,end_len]))
        
        # print(start_ft.size(),end_ft.size(),act_ft.size(),comp_ft.size())
        # exit()
        fts_all_act.append(act_ft)
        fts_all_comp.append(comp_ft)
        comp_all_len.append(comp_len)

    fts_all_act = torch.stack(fts_all_act)
    fts_all_comp = torch.stack(fts_all_comp)
    comp_all_len=torch.stack(comp_all_len)
    # print(comp_all_len.size())
    return fts_all_act, fts_all_comp,comp_all_len
def My_Pooling(index,val_mode=False):
    if val_mode==False:
        savepath='/mnt/sdb/mnt/sda/sunche/work/PGCN-master/mydata_train/'
    else:
        savepath='/mnt/sdb/mnt/sda/sunche/work/PGCN-master/mydata_val/'
    fts_all_act=np.load(savepath+'fts_all_act_tensor('+str(index)+').npy')
    fts_all_comp=np.load(savepath+'fts_all_comp_tensor('+str(index)+').npy')
    prop_type=np.load(savepath+'prop_type_tensor('+str(index)+').npy')[0]
    prop_labels=np.load(savepath+'prop_labels_tensor('+str(index)+').npy')[0]
    prop_reg_targets=np.load(savepath+'prop_reg_targets_tensor('+str(index)+').npy')[0]

    return torch.from_numpy(fts_all_act),torch.from_numpy(fts_all_comp),torch.from_numpy(prop_type),torch.from_numpy(prop_labels),torch.from_numpy(prop_reg_targets)
    # print(index)
    # exit()
def Attention_Pooling(prop_indices, vid, ft_path, n_frame, n_seg=1,index=0,val_mode=False):

    ft_tensor = torch.load(os.path.join(ft_path, vid)).float()
    fts_all_act = []
    fts_all_comp = []
    

    for prop in prop_indices:
        act_s = prop[0]
        act_e = prop[1]
        comp_s = prop[2]
        comp_e = prop[3]

        fp=open('/mnt/sdb/mnt/sda/sunche/dataset/Temporal_action_localization/anet_cuhk_stride5/'+vid+'.pickle','rb')
        features = pickle.load(fp,encoding='bytes')
        start_ft,start_seg = myfeature_pooling(comp_s,act_s,features)
        # print(start_ft)
        # exit()
        end_ft,end_seg = myfeature_pooling(act_e,comp_e,features)
        act_ft,act_seg = myfeature_pooling(act_s,act_e,features)
        # start_ft = feature_pooling(comp_s, act_s, vid,
                                  # n_frame, n_seg, 'max', ft_tensor)
        # end_ft = feature_pooling(act_e, comp_e, vid,
                                  # n_frame, n_seg, 'max', ft_tensor)
        # act_ft = feature_pooling(act_s, act_e, vid,
                                  # n_frame, n_seg, 'max', ft_tensor)
        # comp_ft = [start_ft, act_ft, end_ft]
        # comp_ft = torch.cat(comp_ft, dim=0)

        # fts_all_act.append(act_ft)
        # fts_all_comp.append(comp_ft)


    # fts_all_act = torch.stack(fts_all_act)
    # fts_all_comp = torch.stack(fts_all_comp)

    return start_ft,end_ft,act_ft,start_seg,end_seg,act_seg

def myfeature_pooling(sf,ef,features):
    input_classlabel=np.zeros((1,21))
    input_isaction=np.zeros((1,1))
    input_boundce=np.zeros((1,2))
    input_seg=np.zeros((1,))
    input_beta=np.zeros((1,32,))
    input_data=np.zeros((32,400*int(15/5)))
    allframe=int(np.size(features,0)*5)
    sf_context=int(max(sf,1))
    # input_sf_context[i%batchsize]=sf_context
    ef_context=int(min(ef,allframe))
    seg_num_context=int(math.floor((ef_context-sf_context+1)/15))
    input_seg[0]=seg_num_context
    # for p in range(seg_num_context):
        # for sl in range(int(15/5)):
            # input_data[0,p,sl*400:(sl+1)*400]=features[int((sf_context+15*p-1)/5)+sl,:]/np.linalg.norm(features[int((sf_context+15*p-1)/5+sl),:])
    if seg_num_context<=32:
      for p in range(seg_num_context):
        for sl in range(int(15/5)):
            input_data[p,sl*400:(sl+1)*400]=features[int((sf_context+15*p-1)/5)+sl,:]/np.linalg.norm(features[int((sf_context+15*p-1)/5+sl),:])
    else:
      for p in range(32):
        for sl in range(int(15/5)):
            dur=int(math.floor((ef_context-sf_context+1)/32))
            input_data[p,sl*400:(sl+1)*400]=features[int((sf_context+dur*p-1)/5)+sl,:]/np.linalg.norm(features[int((sf_context+dur*p-1)/5+sl),:])
    # final_input_data=np.reshape(np.transpose(input_data, (2,0,1)),[400*int(15/5),32*1])
    return input_data,input_seg
    # final_input_data=np.reshape(np.transpose(input_data, (2,0,1)),[400*int(15/5),32*1])
    # feat=session.run([network.state_CNN2[0][-1]],feed_dict={
                # network.ground_truth: input_classlabel,
                # network.isaction: input_isaction,
                # network.beta: input_beta,
                # network.x_CNN_raw: final_input_data,
                # network.seg_num: input_seg,
                # network.gt_boundce: input_boundce,
    # return torch.from_numpy(feat)
                # network.dropout_rate: 1,}) 
                
def feature_pooling(start_ind, end_ind, vid, n_frame, n_seg, type, ft_tensor):
    #for turn
    interval = 8
    clip_length = 64

    fts = []
    fts_all = []
    length = 0
    offsets, average_duration = sample_indices(start_ind, end_ind, n_seg)

    ft_num = ft_tensor.size()[0]
    # print(vid,n_frame,ft_tensor.size())
    # print(len(offsets))
    # for off in offsets:
    for i, off in enumerate(offsets):
        start_unit = int(min(ft_num-1, np.floor(float(start_ind+off)/interval)))
        end_unit = int(min(ft_num-2, np.ceil(float(end_ind-clip_length)/interval)))
        if i < n_seg-1:
            start_unit2 = int(min(ft_num-1, np.floor(float(start_ind+offsets[i+1])/interval)))
        else:
            start_unit2 = end_unit
        
        if length>0:
            # fts.append(torch.zeros([1024]))
            fts_all.append(torch.zeros([1024]))
            continue
        if start_unit < end_unit:
            # fts.append(torch.max(ft_tensor[start_unit: end_unit+1, :], 0)[0])
            fts_all.append(torch.max(ft_tensor[start_unit: start_unit2, :], 0)[0])
            # fts=torch.max(ft_tensor[start_unit: start_unit2, :], 0)[0]
        else:
            fts_all.append(ft_tensor[start_unit])
            # fts=ft_tensor[start_unit]
            length=i+1
            
        # fts_all.append(fts)
        # print(start_ind,off,end_ind,(start_unit,start_unit2,end_unit),length)
    if (length==0):
        # print('error!')
        length = 4
        # print(start_ind,off,end_ind,(start_unit,start_unit2,end_unit),length)
    fts_all = torch.stack(fts_all)
    # print(len(offsets),fts_all.size())
    return fts_all.squeeze(),length 

def sample_indices(start, end, num_seg):
    """
    :param record: VideoRecord
    :return: list
    """
    valid_length = end - start
    average_duration = (valid_length + 1) // num_seg
    # print(valid_length,average_duration)
    if average_duration > 0:
        # normal cases
        offsets = np.multiply(list(range(num_seg)), average_duration)
    elif valid_length > num_seg:
        offsets = np.sort(randint(valid_length, size=num_seg))
    else:
        offsets = np.zeros((num_seg, ))

    return offsets, average_duration
